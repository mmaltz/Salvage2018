######################################
## Part 2 - data wrangling
# By CN
# 04/03/2018
#'/Users/maltz/Desktop/RdataBreathe/
# Preliminaries
setwd('/Users/maltz/Desktop/RdataBreathe')
list.files()
library(readr)
all_otus_melt <- read_csv("all_otus_melt4.csv")
View(all_otus.melt)
View(all_otus_melt)
library(readxl)
library(dplyr)
library(reshape2)
library(tidyr)
library(vegan)
library(ggplot2)# ggplot resource -http://rpubs.com/collnell/ggplot2
library(tidyverse) # useful packages in 1 - dplyr, ggplot2, tidyr +
## read in data and clean up variable codings
library(data.table) #fread function
list.files()
otus<-(all_otus.melt)%>% # reads in large datasets faster than 'read.csv'
filter(count >= 1)%>% # drop 0 abundance data
unite(col='taxa', kingdom:species, remove=TRUE)%>%
group_by(sample, taxa)%>% # set grouping level you want data aggregated at
summarize(otu_abun = sum(count), otu_rich =length(unique(SID))) #%>% # summarize the abundances at desired level - here is just each unique ID x taxa (so every otu)
list.files()
library(readr)
all_otus.melt <- read_csv("all_otus_melt4.csv")
View(all_otus.melt)
library(readxl)
library(dplyr)
library(reshape2)
library(tidyr)
library(vegan)
library(ggplot2)# ggplot resource -http://rpubs.com/collnell/ggplot2
library(tidyverse) # useful packages in 1 - dplyr, ggplot2, tidyr +
## read in data and clean up variable codings
library(data.table) #fread function
list.files()
otus<-(all_otus.melt)%>% # reads in large datasets faster than 'read.csv'
filter(count >= 1)%>% # drop 0 abundance data
unite(col='taxa', kingdom:species, remove=TRUE)%>%
group_by(sample, taxa)%>% # set grouping level you want data aggregated at
summarize(otu_abun = sum(count), otu_rich =length(unique(SID))) #%>% # summarize the abundances at desired level - here is just each unique ID x taxa (so every otu)
---
title: "breathe"
author: "M. Maltz"
date: "10/03/2018"
output:
html_document:
toc: TRUE
toc_float: TRUE
toc_depth: 4
---
```{r, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, tidy=TRUE,error = TRUE, eval = TRUE, message = FALSE, warning = FALSE, rows.print=5, cols.min.print=4, fig.width=6, fig.height=4.5)
```
```{r Load preliminary packages, include=FALSE}
library(dplyr) ## for data wrangling - %>% function
library(reshape2) ##melt and cast data
library(tidyr) # 'separate' function
library(readxl) #read xlsx files into r on mac computer
library(vegan) # dissimilarity matrix, permanova functions
library(tidyverse)
library(stringr)
library(ggplot2) # plotting
library(magrittr)
library(cowplot)
library(formatR)
---
title: "breathe"
author: "M. Maltz"
date: "10/03/2018"
output:
html_document:
toc: TRUE
toc_float: TRUE
toc_depth: 4
---
```{r, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, tidy=TRUE,error = TRUE, eval = TRUE, message = FALSE, warning = FALSE, rows.print=5, cols.min.print=4, fig.width=6, fig.height=4.5)
```
```{r Load preliminary packages, include=FALSE}
library(dplyr) ## for data wrangling - %>% function
library(reshape2) ##melt and cast data
library(tidyr) # 'separate' function
library(readxl) #read xlsx files into r on mac computer
library(vegan) # dissimilarity matrix, permanova functions
library(tidyverse)
library(stringr)
library(ggplot2) # plotting
library(magrittr)
library(cowplot)
library(formatR)
knitr::opts_chunk$set(cache=TRUE, tidy=TRUE,error = TRUE, eval = TRUE, message = FALSE, warning = FALSE, rows.print=5, cols.min.print=4, fig.width=6, fig.height=4.5)
library(dplyr) ## for data wrangling - %>% function
library(reshape2) ##melt and cast data
library(tidyr) # 'separate' function
library(readxl) #read xlsx files into r on mac computer
library(vegan) # dissimilarity matrix, permanova functions
library(tidyverse)
library(stringr)
library(ggplot2) # plotting
library(magrittr)
library(cowplot)
library(formatR)
map6<-read.csv("breathe_metadata.csv", header = TRUE, col.names =   c("sample","ChambStatus","group","rep","description"))
str(map6)
unique(map6$ChambStatus)
# bacteria otu
B16S<-read.csv("BreatheTable1.csv", header = TRUE, stringsAsFactors = FALSE)
# split taxa groupings into new columns
source('dust_functions.R')
B16S<-split_taxa(B16S)
# extract the string between k__ and ; for the kingdoms
B16S$kingdom<-str_match(B16S$taxonomy, "k__(.*?);")[,2] #regex
# do the same for other taxa groupings
B16S$phylum<-str_match(B16S$taxonomy, "p__(.*?);")[,2]
B16S$class<-str_match(B16S$taxonomy, "c__(.*?);")[,2]
B16S$order<-str_match(B16S$taxonomy, "o__(.*?);")[,2]
B16S$family<-str_match(B16S$taxonomy, "f__(.*?);")[,2]
B16S$genus<-str_match(B16S$taxonomy, "g__(.*?);")[,2]
B16S$species<-str_match(B16S$taxonomy, "s__(.*?)$")[,2]
View(B16S)
write.csv(B16S, '/Users/maltz/Desktop/RdataBreathe/otus_by_columnSplit.csv', row.names=FALSE)
str(map6) #grouping variables
colnames(B16S) # community data
otu.taxa<-B16S%>%dplyr::select(OTUID, kingdom:species)
write.csv(otu.taxa, 'data/OTU_taxa_id.csv', row.names=FALSE) # save full # reorder columns data
otu.melt<-B16S%>%dplyr::select(-taxonomy:-species)%>%
dplyr::select(OTUID, everything())%>%
melt(id.vars=c('OTU'), variable.name='SampleID')
otu.melt<-B16S%>%dplyr::select(-taxonomy:-species)%>%
dplyr::select(OTUID, everything())%>%
melt(id.vars=c('OTUID'), variable.name='SampleID')
# remove singletons and doubletons
otu.melt$value_clean<-ifelse(otu.melt$value <= 2, NA, otu.melt$value)
# community df using cleaned data
otu.cast<-otu.melt%>%dcast(SampleID~OTU, value.var = 'value_clean')
otu.melt<-B16S%>%dplyr::select(-taxonomy:-species)%>%
dplyr::select(OTUID, everything())%>%
melt(id.vars=c('OTUID'), variable.name='SampleID')
# remove singletons and doubletons
otu.melt$value_clean<-ifelse(otu.melt$value <= 2, NA, otu.melt$value)
# community df using cleaned data
otu.cast<-otu.melt%>%dcast(SampleID~OTUID, value.var = 'value_clean')
## remove otus that were dropped with singletons and doubletons
otu.mat<-otu.cast[,-1]
otu.new<-otu.mat[,colSums(otu.mat, na.rm=TRUE)> 0]
otu.new<-otu.new%>%mutate(SampleID=otu.cast$SampleID)%>%dplyr::select(SampleID, everything())
write.csv(otu.new, 'data/OTU_community_clean.csv', row.names=FALSE)
otu.taxa<-read.csv('data/OTU_taxa_id.csv') # otu ids
otu.comm<-read.csv('data/OTU_community_clean.csv')
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
#otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
# this says - for the community df, order the rows to match the order of the column names in unifrac, that match to SampleID
# reorder mapping data to community data
#grps<-map6[match(colnames(unifrac), map6$SampleID),]
# now that all the data (community, distances, grouping variables) are ordered the same, we can use permanova etc
# Elevation is integer - change to factor
grps$ChambStatus<-as.factor(grps$Elevation)
dist.bc<-vegdist(otu.comm[,-1], method='bray', na.rm=TRUE)
ad.bc<-adonis2(dist.bc~ChambStatus, data=grps, permutations=1000)
# Elevation is integer - change to factor
grps$ChambStatus<-as.factor(grps$ChambStatus)
#unifrac distances
str(grps) #look at data types to indetify error source
View(ssugenusREADRICHlong)
---
title: "AMF Test27"
author: "M. Maltz"
date: '20180927'
output:
html_document: default
pdf_document: default
---
### Logic
Salvage topsoil was removed from a donor site and delivered to three recipient sites in 2015. We sampled all sites (Donor and recipients) prior to topsoil delivery and sequenced AM Fungi from all sites in 2015 and 2017 from manipulative plots, set up in a randomized block design at each site with: control treatments (no topsoil added), a dusting of topsoil, and three levels of topsoil thicknesses (2", 4" and 6" thick layers of this topsoil, originating from the donor site)), delivered to all recipient sites).
```{r}
knitr::opts_chunk$set(cache=TRUE, tidy=TRUE, error = FALSE, eval = TRUE, message = FALSE, warning = FALSE, rows.print=5, cols.min.print=4, fig.width=6, fig.height=4.5)
```
### Questions:
###**Q1:
Propagule determination: Do AM fungal communities resemble the donor site, regardless of where soil was delivered? Is provenance a driver of AM fungal community composition?
###**Q2:
Environmental filtering: Do AM fungal communities resemble the recipient sites, and are more dissimilar to the AM fungal communities from the donor site?
###**Q3:
Propagule pressure: Do AM fungal communities resemble the donor site more in higher level topsoil treatments, than they do in the control or dusted sites?
####**Outputs:**
#Analysis of similarity:
Determine the similarity of AMF communities at each recipient site to the donor site, from where topsoils originated from.
Generate heatmaps with distances, to visually determine - which sites/samples are more similar to each other, and which are more dissimilar.
Generate NMDS / Pcoa, plotted with Year as shapes and Sites as colors, and Description as ...?
Run permanova
Do AM fungal communities at each site resemble the recipient sites, and are they more dissimilar to the donor sites?
#Functional group richness:
Determine the richness of AMF functional groups in the donor site, from where topsoils originated from, and in the recipient sites pre-topsoil delivery (pre-treatment), and post-topsoil delivery (post-treatment)
#Taxonomic diversity:
Determine the OTU taxa richness (alpha diversity) of AMF communities in the donor site, from where topsoils originated from, and in the recipient sites pre-topsoil delivery (pre-treatment), and post-topsoil delivery (post-treatment).
Determine the beta diversity of AMF communities in the donor site, from where topsoils originated from, and in the recipient sites pre-topsoil delivery (pre-treatment), and post-topsoil delivery (post-treatment).
#Topsoil level treatments
Propagule pressure: Do AM fungal communities resemble the donor site more in thicker topsoil layer treatments than they do in the control or dusted sites?
Are the sites with Treat groups = S, more similar to the donor site than F, and are treatment groups S and F more similar to the donor site than T? Is this relationship clinal, with S being the thickest and most similar to donor site, followed by F, and then by T.
TO FIGURE OUT - how to address this question statistically??multiple regression with Treat on the X and similarity to Donor Site on the Y?? A permanova with multiple comparisons?
```{r}
knitr::opts_chunk$set(cache=TRUE, tidy=TRUE, error = FALSE, eval = TRUE, message = FALSE, warning = FALSE, rows.print=5, cols.min.print=4, fig.width=6, fig.height=4.5)
```
Load Required Packages
```{r}
library(tidyverse)
library(dplyr) ## for data wrangling - %>% function
library(reshape2)  ##melt and cast data
library(ggplot2) # plotting
library(data.table)
library(stringr)
library(tidyr) # 'separate' function
library(readxl) #read xlsx files into r on mac computer
library(vegan) # dissimilarity matrix, permanova functions
library(magrittr)
library(cowplot)
library(formatR)
date<-format(Sys.time(), '%Y%b%d')
date
setwd('/Users/maltz/Desktop/RdataBreathe')
list.files()
library(readr)
#all_otus_melt <- read_csv("all_otus_melt.csv")
View(all_otus.melt)
library(readxl)
library(dplyr)
library(reshape2)
library(tidyr)
library(vegan)
library(ggplot2)# ggplot resource -http://rpubs.com/collnell/ggplot2
library(tidyverse) # useful packages in 1 - dplyr, ggplot2, tidyr +
knitr::opts_chunk$set(cache=TRUE, tidy=TRUE,error = TRUE, eval = TRUE, message = FALSE, warning = FALSE, rows.print=5, cols.min.print=4, fig.width=6, fig.height=4.5)
library(dplyr) ## for data wrangling - %>% function
library(reshape2) ##melt and cast data
library(tidyr) # 'separate' function
library(readxl) #read xlsx files into r on mac computer
library(vegan) # dissimilarity matrix, permanova functions
library(tidyverse)
library(stringr)
library(ggplot2) # plotting
library(magrittr)
library(cowplot)
library(formatR)
map6<-read.csv("breathe_metadata.csv", header = TRUE, col.names =   c("sample","ChambStatus","group","rep","description"))
str(map6)
unique(map6$ChambStatus)
# bacteria otu
B16S<-read.csv("BreatheTable1.csv", header = TRUE, stringsAsFactors = FALSE)
# split taxa groupings into new columns
source('dust_functions.R')
B16S<-split_taxa(B16S)
# extract the string between k__ and ; for the kingdoms
B16S$kingdom<-str_match(B16S$taxonomy, "k__(.*?);")[,2] #regex
# do the same for other taxa groupings
B16S$phylum<-str_match(B16S$taxonomy, "p__(.*?);")[,2]
B16S$class<-str_match(B16S$taxonomy, "c__(.*?);")[,2]
B16S$order<-str_match(B16S$taxonomy, "o__(.*?);")[,2]
B16S$family<-str_match(B16S$taxonomy, "f__(.*?);")[,2]
B16S$genus<-str_match(B16S$taxonomy, "g__(.*?);")[,2]
B16S$species<-str_match(B16S$taxonomy, "s__(.*?)$")[,2]
View(B16S)
write.csv(B16S, '/Users/maltz/Desktop/RdataBreathe/otus_by_columnSplit.csv', row.names=FALSE)
# extract the string between k__ and ; for the kingdoms
B16S$kingdom<-str_match(B16S$taxonomy, "k__(.*?);")[,2] #regex
# do the same for other taxa groupings
B16S$phylum<-str_match(B16S$taxonomy, "p__(.*?);")[,2]
B16S$class<-str_match(B16S$taxonomy, "c__(.*?);")[,2]
B16S$order<-str_match(B16S$taxonomy, "o__(.*?);")[,2]
B16S$family<-str_match(B16S$taxonomy, "f__(.*?);")[,2]
B16S$genus<-str_match(B16S$taxonomy, "g__(.*?);")[,2]
B16S$species<-str_match(B16S$taxonomy, "s__(.*?)$")[,2]
View(B16S)
write.csv(B16S, '/Users/maltz/Desktop/RdataBreathe/otus_by_columnSplit.csv', row.names=FALSE)
str(map6) #grouping variables
colnames(B16S) # community data
otu.taxa<-B16S%>%dplyr::select(OTUID, kingdom:species)
write.csv(otu.taxa, 'data/OTU_taxa_id.csv', row.names=FALSE) # save full # reorder columns data
otu.melt<-B16S%>%dplyr::select(-taxonomy:-species)%>%
dplyr::select(OTUID, everything())%>%
melt(id.vars=c('OTUID'), variable.name='SampleID')
# remove singletons and doubletons
otu.melt$value_clean<-ifelse(otu.melt$value <= 2, NA, otu.melt$value)
# community df using cleaned data
otu.cast<-otu.melt%>%dcast(SampleID~OTUID, value.var = 'value_clean')
## remove otus that were dropped with singletons and doubletons
otu.mat<-otu.cast[,-1]
otu.new<-otu.mat[,colSums(otu.mat, na.rm=TRUE)> 0]
otu.new<-otu.new%>%mutate(SampleID=otu.cast$SampleID)%>%dplyr::select(SampleID, everything())
write.csv(otu.new, 'data/OTU_community_clean.csv', row.names=FALSE)
otu.taxa<-read.csv('data/OTU_taxa_id.csv') # otu ids
otu.comm<-read.csv('data/OTU_community_clean.csv')
unifrac<-read.table('data/unweighted_unifrac_dm.txt')
unifrac<-read.table('data/unweighted_unifrac_dm.txt')
knitr::opts_chunk$set(cache=TRUE, tidy=TRUE,error = TRUE, eval = TRUE, message = FALSE, warning = FALSE, rows.print=5, cols.min.print=4, fig.width=6, fig.height=4.5)
library(dplyr) ## for data wrangling - %>% function
library(reshape2) ##melt and cast data
library(tidyr) # 'separate' function
library(readxl) #read xlsx files into r on mac computer
library(vegan) # dissimilarity matrix, permanova functions
library(tidyverse)
library(stringr)
library(ggplot2) # plotting
library(magrittr)
library(cowplot)
library(formatR)
map6<-read.csv("breathe_metadata.csv", header = TRUE, col.names =   c("sample","ChambStatus","group","rep","description"))
str(map6)
unique(map6$ChambStatus)
# bacteria otu
B16S<-read.csv("BreatheTable1.csv", header = TRUE, stringsAsFactors = FALSE)
# split taxa groupings into new columns
source('dust_functions.R')
B16S<-split_taxa(B16S)
# extract the string between k__ and ; for the kingdoms
B16S$kingdom<-str_match(B16S$taxonomy, "k__(.*?);")[,2] #regex
# do the same for other taxa groupings
B16S$phylum<-str_match(B16S$taxonomy, "p__(.*?);")[,2]
B16S$class<-str_match(B16S$taxonomy, "c__(.*?);")[,2]
B16S$order<-str_match(B16S$taxonomy, "o__(.*?);")[,2]
B16S$family<-str_match(B16S$taxonomy, "f__(.*?);")[,2]
B16S$genus<-str_match(B16S$taxonomy, "g__(.*?);")[,2]
B16S$species<-str_match(B16S$taxonomy, "s__(.*?)$")[,2]
View(B16S)
write.csv(B16S, '/Users/maltz/Desktop/RdataBreathe/otus_by_columnSplit.csv', row.names=FALSE)
knitr::opts_chunk$set(cache=TRUE, tidy=TRUE,error = TRUE, eval = TRUE, message = FALSE, warning = FALSE, rows.print=5, cols.min.print=4, fig.width=6, fig.height=4.5)
library(dplyr) ## for data wrangling - %>% function
library(reshape2) ##melt and cast data
library(tidyr) # 'separate' function
library(readxl) #read xlsx files into r on mac computer
library(vegan) # dissimilarity matrix, permanova functions
library(tidyverse)
library(stringr)
library(ggplot2) # plotting
library(magrittr)
library(cowplot)
library(formatR)
map6<-read.csv("breathe_metadata.csv", header = TRUE, col.names =   c("sample","ChambStatus","group","rep","description"))
str(map6)
unique(map6$ChambStatus)
# bacteria otu
B16S<-read.csv("BreatheTable1.csv", header = TRUE, stringsAsFactors = FALSE)
# split taxa groupings into new columns
source('dust_functions.R')
B16S<-split_taxa(B16S)
otu.taxa<-read.csv('data/OTU_taxa_id.csv') # otu ids
otu.comm<-read.csv('data/OTU_community_clean.csv')
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
#otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
# this says - for the community df, order the rows to match the order of the column names in unifrac, that match to SampleID
# reorder mapping data to community data
#grps<-map6[match(colnames(unifrac), map6$SampleID),]
# now that all the data (community, distances, grouping variables) are ordered the same, we can use permanova etc
set.seed(304)
#unifrac distances
str(grps) #look at data types to indetify error source
unifrac<-read.table('data/unweighted_unifrac_dm.txt')
unifrac<-read.table('data/unweighted_unifrac_dm.txt')
unifrac<-read.table('unweighted_unifrac_dm.txt')
#unifrac_wt<-read.table('data/weighted_unifrac_dm.txt')
unifrac.melt<-unifrac%>%melt(variable.name='otu_1')%>%
mutate(otu_2 = rep.int(colnames(unifrac), times=length(colnames(unifrac))))
heat.uni<-ggplot(data = unifrac.melt, aes(x = reorder(otu_1, value), y = reorder(otu_2, value)))+
geom_tile(aes(fill = value))+
scale_fill_gradient2(low = 'midnightblue', mid='deepskyblue3', high='yellow', midpoint = .5)+
theme(axis.text.x = element_text(angle=90),axis.text = element_text(size=9))+
labs(x='Sample', y='Sample', title='unweighted')
heat.uni<-ggplot(data = unifrac.melt, aes(x = reorder(otu_1, value), y = reorder(otu_2, value)))+
geom_tile(aes(fill = value))+
scale_fill_gradient2(low = 'midnightblue', mid='deepskyblue3', high='yellow', midpoint = .5)+
theme(axis.text.x = element_text(angle=90),axis.text = element_text(size=9))+
labs(x='Sample', y='Sample', title='unweighted')
unifrac.melt<-unifrac_wt%>%melt(variable.name='otu_1')%>%
mutate(otu_2 = rep.int(colnames(unifrac_wt), times=length(colnames(unifrac_wt))))
unifrac.melt<-unifrac%>%melt(variable.name='otu_1')%>%
mutate(otu_2 = rep.int(colnames(unifrac), times=length(colnames(unifrac_wt))))
unifrac.melt<-unifrac%>%melt(variable.name='otu_1')%>%
mutate(otu_2 = rep.int(colnames(unifrac), times=length(colnames(unifrac))))
heat<-ggplot(data = unifrac.melt, aes(x = reorder(otu_1, value), y = reorder(otu_2, value)))+
geom_tile(aes(fill = value))+
scale_fill_gradient2(low = 'midnightblue', mid='deepskyblue3', high='yellow', midpoint = .5)+
theme(axis.text.x = element_text(angle=90),axis.text = element_text(size=9))+
labs(x='Sample', y='Sample', title='weighted')
heat<-ggplot(data = unifrac.melt, aes(x = reorder(otu_1, value), y = reorder(otu_2, value)))+
geom_tile(aes(fill = value))+
scale_fill_gradient2(low = 'midnightblue', mid='deepskyblue3', high='yellow', midpoint = .5)+
theme(axis.text.x = element_text(angle=90),axis.text = element_text(size=9))+
labs(x='Sample', y='Sample', title='weighted')
heat<-ggplot(data = unifrac.melt, aes(x = reorder(otu_1, value), y = reorder(otu_2, value)))+
geom_tile(aes(fill = value))+
scale_fill_gradient2(low = 'midnightblue', mid='deepskyblue3', high='yellow', midpoint = .5)+
theme(axis.text.x = element_text(angle=90),axis.text = element_text(size=9))+
labs(x='Sample', y='Sample', title='weighted')
heat<-ggplot(data = unifrac.melt, aes(x = reorder(otu_1, value), y = reorder(otu_2, value)))+
geom_tile(aes(fill = value))+
scale_fill_gradient2(low = 'midnightblue', mid='deepskyblue3', high='yellow', midpoint = .5)+
theme(axis.text.x = element_text(angle=90),axis.text = element_text(size=9))+
labs(x='Sample', y='Sample', title='weighted')
plot_grid(heat.uni, heat, nrow=1, ncol=2)
plot_grid(heat.uni, heat.wt, nrow=1, ncol=2)
str(map6) #grouping variables
colnames(B16S) # community data
otu.taxa<-B16S%>%dplyr::select(OTUID, kingdom:species)
write.csv(otu.taxa, 'data/OTU_taxa_id.csv', row.names=FALSE) # save full # reorder columns data
otu.melt<-B16S%>%dplyr::select(-taxonomy:-species)%>%
dplyr::select(OTUID, everything())%>%
melt(id.vars=c('OTUID'), variable.name='SampleID')
# remove singletons and doubletons
otu.melt$value_clean<-ifelse(otu.melt$value <= 2, NA, otu.melt$value)
# community df using cleaned data
otu.cast<-otu.melt%>%dcast(SampleID~OTUID, value.var = 'value_clean')
## remove otus that were dropped with singletons and doubletons
otu.mat<-otu.cast[,-1]
otu.new<-otu.mat[,colSums(otu.mat, na.rm=TRUE)> 0]
otu.new<-otu.new%>%mutate(SampleID=otu.cast$SampleID)%>%dplyr::select(SampleID, everything())
write.csv(otu.new, 'data/OTU_community_clean.csv', row.names=FALSE)
otu.taxa<-read.csv('data/OTU_taxa_id.csv') # otu ids
otu.comm<-read.csv('data/OTU_community_clean.csv')
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
# this says - for the community df, order the rows to match the order of the column names in unifrac, that match to SampleID
# reorder mapping data to community data
grps<-map6[match(colnames(unifrac), map6$SampleID),]
# now that all the data (community, distances, grouping variables) are ordered the same, we can use permanova etc
set.seed(304)
#unifrac distances
str(grps) #look at data types to indetify error source
# Elevation is integer - change to factor
grps$ChambStatus<-as.factor(grps$ChambStatus)
grps$rep<-as.factor(grps$rep)
ad.uni<-adonis2(unifrac~ChambStatus+rep, data=grps, permutations=1000)
?"%in%"
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
# this says - for the community df, order the rows to match the order of the column names in unifrac, that match to SampleID
# reorder mapping data to community data
grps<-map6[match(colnames(unifrac), map6$SampleID),]
# now that all the data (community, distances, grouping variables) are ordered the same, we can use permanova etc
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
# this says - for the community df, order the rows to match the order of the column names in unifrac, that match to SampleID
# reorder mapping data to community data
grps<-map6[match(colnames(unifrac), map6$SampleID),]
write.csv((grps, '/Users/maltz/Desktop/breathe_grps.csv', row.names=FALSE))
write.csv(grps, '/Users/maltz/Desktop/breathe_grps.csv', row.names=FALSE))
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
# this says - for the community df, order the rows to match the order of the column names in unifrac, that match to SampleID
# reorder mapping data to community data
grps<-map6[match(colnames(unifrac), map6$SampleID),]
write.csv(grps, 'breathe_grps.csv', row.names=FALSE))
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
# this says - for the community df, order the rows to match the order of the column names in unifrac, that match to SampleID
# reorder mapping data to community data
grps<-map6[match(colnames(unifrac), map6$SampleID),]
write.csv((grps, 'breathe_grps.csv', row.names=FALSE))
## the samples in the unifrac dist and community need to be in the same order
# need to order community based on unifraq
# make new df based on unifrac, matched to same order as unifrac
# match the order to colnames(unifrac), rewrite over same name
otu.comm<-otu.comm[match(colnames(unifrac), otu.comm$SampleID),]
# this says - for the community df, order the rows to match the order of the column names in unifrac, that match to SampleID
# reorder mapping data to community data
grps<-map6[match(colnames(unifrac), map6$SampleID),]
write.csv((grps, 'breathe_grps.csv', row.names=FALSE))
#unifrac distances
str(grps) #look at data types to indetify error source
# Elevation is integer - change to factor
grps$ChambStatus<-as.factor(grps$ChambStatus)
grps$rep<-as.factor(grps$Month)
ls
getwd()
setwd("/Users/maltz/Documents/Salvage2018")
ls()
dir()
getwd()
ls()
getwd
getwd()
quit()
